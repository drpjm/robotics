
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3.2. Actions over time &#8212; Introduction to Robotics and Perception</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3.3. Dynamic Bayes Nets" href="S33_vacuum_sensing.html" />
    <link rel="prev" title="3.1. Modeling the State of the Vacuum Cleaning Robot" href="S31_vacuum_state.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-312077-7', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Robotics and Perception</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction to Robotics and Perception
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S10_introduction.html">
   1. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S11_intro_state.html">
     1.1. Representing State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S12_intro_actions.html">
     1.2. Robot Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S13_intro_sensing.html">
     1.3. Sensing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S14_intro_perception.html">
     1.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S15_intro_decision.html">
     1.5. Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S16_intro_learning.html">
     1.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S20_sorter_intro.html">
   2. A Trash Sorting Robot
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S21_sorter_state.html">
     2.1. Modeling the World State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S22_sorter_actions.html">
     2.2. Actions for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S23_sorter_sensing.html">
     2.3. Sensors for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S24_sorter_perception.html">
     2.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S25_sorter_decision_theory.html">
     2.5. Decision Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S26_sorter_learning.html">
     2.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="S30_vacuum_intro.html">
   3. A Robot Vacuum Cleaner
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="S31_vacuum_state.html">
     3.1. Modeling the State of the Vacuum Cleaning Robot
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.2. Actions over time
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S33_vacuum_sensing.html">
     3.3. Dynamic Bayes Nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S34_vacuum_perception.html">
     3.4. Perception with Graphical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S35_vacuum_decision.html">
     3.5. Markov Decision Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S36_vacuum_RL.html">
     3.6. Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S40_logistics_intro.html">
   4. Warehouse Robots in 2D
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S41_logistics_state.html">
     4.1. Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S42_logistics_actions.html">
     4.2. Moving in 2D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S43_logistics_sensing.html">
     4.3. Sensor Models with Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S44_logistics_perception.html">
     4.4. Localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S45_logistics_planning.html">
     4.5. Planning for Logistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S46_logistics_learning.html">
     4.6. Some System Identification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S50_diffdrive_intro.html">
   5. A Mobile Robot With Simple Kinematics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S51_diffdrive_state.html">
     5.1. State Space for a Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S52_diffdrive_actions.html">
     5.2. Motion Model for the Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S53_diffdrive_sensing.html">
     5.3. Robot Vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S54_diffdrive_perception.html">
     5.4. Computer Vision 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S55_diffdrive_planning.html">
     5.5. Path Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S56_diffdrive_learning.html">
     5.6. Deep Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S60_driving_intro.html">
   6. Autonomous Vehicles
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S61_driving_state.html">
     6.1. Planar Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S62_driving_actions.html">
     6.2. Kinematics for Driving
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S63_driving_sensing.html">
     6.3. Sensing for Autonomous Vehicles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S64_driving_perception.html">
     6.4. SLAM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S65_driving_planning.html">
     6.5. Planning for Autonomous Driving.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S66_driving_DRL.html">
     6.6. Deep Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S70_drone_intro.html">
   7. Autonomous Drones in 3D
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S71_drone_state.html">
     7.1. Moving in Three Dimensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S72_drone_actions.html">
     7.2. Multi-rotor Aircraft
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S73_drone_sensing.html">
     7.3. Sensing for Drones
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S74_drone_perception.html">
     7.4. Visual SLAM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S75_drone_planning.html">
     7.5. Trajectory Optimization
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/S32_vacuum_actions.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/gtbook/robotics"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS32_vacuum_actions.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/gtbook/robotics/main?urlpath=tree/S32_vacuum_actions.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#primitive-actions">
   3.2.1. Primitive Actions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probabilistic-outcomes-of-actions">
   3.2.2. Probabilistic Outcomes of Actions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercises">
     3.2.2.1. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computing-the-posterior-distribution-for-a-sequence-of-actions">
   3.2.3. Computing the Posterior Distribution for a Sequence of Actions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#state-transition-matrices-and-the-belief-state">
   3.2.4. State Transition Matrices and the Belief State
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#controlled-markov-chains">
   3.2.5. Controlled Markov Chains
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#forward-simulation">
   3.2.6. Forward Simulation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise">
     3.2.6.1. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayes-nets">
   3.2.7. Bayes Nets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#factored-state-representations">
   3.2.8. Factored State Representations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     3.2.8.1. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gtsam-101">
   3.2.9. GTSAM 101
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Actions over time</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#primitive-actions">
   3.2.1. Primitive Actions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probabilistic-outcomes-of-actions">
   3.2.2. Probabilistic Outcomes of Actions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercises">
     3.2.2.1. Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#computing-the-posterior-distribution-for-a-sequence-of-actions">
   3.2.3. Computing the Posterior Distribution for a Sequence of Actions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#state-transition-matrices-and-the-belief-state">
   3.2.4. State Transition Matrices and the Belief State
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#controlled-markov-chains">
   3.2.5. Controlled Markov Chains
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#forward-simulation">
   3.2.6. Forward Simulation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise">
     3.2.6.1. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayes-nets">
   3.2.7. Bayes Nets
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#factored-state-representations">
   3.2.8. Factored State Representations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     3.2.8.1. Exercise
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gtsam-101">
   3.2.9. GTSAM 101
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S32_vacuum_actions.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="tex2jax_ignore mathjax_ignore section" id="actions-over-time">
<h1><span class="section-number">3.2. </span>Actions over time<a class="headerlink" href="#actions-over-time" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>We can use probability language to describe systems with uncertainty in the effects of actions.</p>
</div></blockquote>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<div align='center'>
<img src='https://github.com/gtbook/robotics/blob/main/Art/steampunk/S32-iRobot%20vacuuming%20robot-01.jpg?raw=1' style='height:256 width:100%'/>
</div>
</div></div>
</div>
<p>In the real world, robots do not always execute actions perfectly, for a
variety of reasons.
To model the uncertainty when executing an action, we will once again use the
language of probability.
We will use <em>conditional probability distributions</em> to model how we can affect the state
of the robot by actions.
Recall that in Chapter 2 we used conditional probabilities to model
the effects of uncertainty in sensing at a specific moment in time.
Here, we use conditional probabilities to model the uncertainty in state transitions when
actions are executed.</p>
<p>We can model this graphically, using directed edges to specify conditional
probabilities on variables.
We can use these graphical models to generate sample system trajectories
for a fixed sequence of actions.
Such sample trajectories can be used for planning, as we will see later in the chapter.
In addition, the graphical model approach allows us to easily extend probabilistic actions to
factored state representations.</p>
<div class="section" id="primitive-actions">
<h2><span class="section-number">3.2.1. </span>Primitive Actions<a class="headerlink" href="#primitive-actions" title="Permalink to this headline">¶</a></h2>
<p>We will assume that our robot is equipped with navigation software that implements four
primitive actions: <em>move left, move right, move up, move down</em>,
which we will denote by <em>L,R,U,D</em>.
Together, these four actions define the <strong>action space</strong>.
The nominal effects of these actions (i.e., the effects of the actions without taking into account uncertainty)
are to move the robot from the current room to an adjacent
room, according to the direction specified by the action.
For example, executing the <em>move down</em> action from the living room should take the robot into the hallway.</p>
<p>We can represent these actions graphically by making a slight modification to our state space graph
from the previous section.
Instead of using undirected edges to denote adjacency, each action contributes a directed edge, as shown in
Figure <a href="#fig:Vacuum" data-reference-type="ref" data-reference="fig:Vacuum">1</a>.
Note that to simplify notation  we use <em>L,R,U,D</em>
instead of <em>move left, move right, move up, move down</em> to label the edges.</p>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/S32-Actions.png?raw=1" id="fig:Stochastic" style="width:14cm" alt="" />
<figcaption id="fig:Stochastic" label="fig:Stochastic">Our robot is equipped with
four primitive actions: Left, Right, Up, and Down.
</figcaption>
</figure></div>
<div class="section" id="probabilistic-outcomes-of-actions">
<h2><span class="section-number">3.2.2. </span>Probabilistic Outcomes of Actions<a class="headerlink" href="#probabilistic-outcomes-of-actions" title="Permalink to this headline">¶</a></h2>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/N3-Mud.png?raw=1" id="fig:Mud" style="width:14cm" alt="" />
<figcaption id="fig:Mud" label="fig:Mud">Mobile robot driving in mud.</figcaption>
</figure>
<p>In the real world, robots do not always execute actions perfectly, for a
variety of reasons. For example, as shown in Figure
<a href="#fig:Mud" data-reference-type="ref" data-reference="fig:Mud">2</a>,
a robot may want to drive forward in an outdoor environment but mud
under its wheels might prevent it from traveling as far as we would like.</p>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/N3-Pick.png?raw=1" id="fig:Pickup" style="width:14cm" alt="" />
<figcaption id="fig:Pickup" label="fig:Pickup">A humanoid attempting to pick up an object.</figcaption>
</figure>
<p>Or a robot with an articulated arm (Figure
<a href="#fig:Pickup" data-reference-type="ref" data-reference="fig:Pickup">3</a>)
might attempt to pick up an object, but fail.</p>
<p>For our vacuum cleaning robot, a variety of things could go wrong: a particular doorway might be blocked, the robot might get lost, or it might take an action that is simply not available in a particular room - for example executing
<em>move up</em> in the office.</p>
<p>To model the uncertainty associated with executing an action, we will once again use the language of probability.
In particular, we will use the conditional probability <span class="math notranslate nohighlight">\(P(X_{t+1}|X_{t}=x,A=a)\)</span> to define
the the <strong>state transition model</strong>  model, i.e.,
the conditional probability distribution for the next state <span class="math notranslate nohighlight">\(X_{t+1}\)</span>,
given the value <span class="math notranslate nohighlight">\(x\)</span> of the current state <span class="math notranslate nohighlight">\(X_{t}\)</span>, and the value <span class="math notranslate nohighlight">\(a\)</span> of the action <span class="math notranslate nohighlight">\(A\)</span>.
Because the state space in this case involves navigation, we also call the corresponding conditional distribution
<span class="math notranslate nohighlight">\(P(X_{t+1}|X_{t},A)\)</span> a <strong>motion model</strong>.</p>
<p>The code below generates a motion model for moving from state <span class="math notranslate nohighlight">\(X_1\)</span> to <span class="math notranslate nohighlight">\(X_2\)</span> in the
form of a large conditional probability table:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># vacuum.action_space = [&quot;L&quot;,&quot;R&quot;,&quot;U&quot;,&quot;D&quot;,]</span>
<span class="c1"># vacuum.action_spec is a string with the transition probabilities:</span>
<span class="c1">#  &quot;1/0/0/0/0 2/8/0/0/0 1/0/0/0/0 2/0/0/8/0</span>
<span class="c1">#   8/2/0/0/0 0/1/0/0/0 0/1/0/0/0 0/2/0/0/8</span>
<span class="c1">#   0/0/1/0/0 0/0/2/8/0 0/0/1/0/0 0/0/1/0/0</span>
<span class="c1">#   0/0/8/2/0 0/0/0/2/8 8/0/0/2/0 0/0/0/1/0</span>
<span class="c1">#   0/0/0/8/2 0/0/0/0/1 0/8/0/0/2 0/0/0/0/1&quot;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span> <span class="c1"># states for times 1,2 and 3</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span> <span class="c1"># actions for times 1 and 2</span>
<span class="n">motion_model</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">motion_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(X2|X1,A1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>X1</i></th><th><i>A1</i></th><th>Living Room</th><th>Kitchen</th><th>Office</th><th>Hallway</th><th>Dining Room</th></tr>
  </thead>
  <tbody>
    <tr><th>Living Room</th><th>L</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>R</th><td>0.2</td><td>0.8</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>U</th><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Living Room</th><th>D</th><td>0.2</td><td>0</td><td>0</td><td>0.8</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>L</th><td>0.8</td><td>0.2</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>R</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>U</th><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
    <tr><th>Kitchen</th><th>D</th><td>0</td><td>0.2</td><td>0</td><td>0</td><td>0.8</td></tr>
    <tr><th>Office</th><th>L</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>R</th><td>0</td><td>0</td><td>0.2</td><td>0.8</td><td>0</td></tr>
    <tr><th>Office</th><th>U</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Office</th><th>D</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><th>Hallway</th><th>L</th><td>0</td><td>0</td><td>0.8</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0.2</td><td>0.8</td></tr>
    <tr><th>Hallway</th><th>U</th><td>0.8</td><td>0</td><td>0</td><td>0.2</td><td>0</td></tr>
    <tr><th>Hallway</th><th>D</th><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
    <tr><th>Dining Room</th><th>L</th><td>0</td><td>0</td><td>0</td><td>0.8</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>R</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>Dining Room</th><th>U</th><td>0</td><td>0.8</td><td>0</td><td>0</td><td>0.2</td></tr>
    <tr><th>Dining Room</th><th>D</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It is of course very tedious to specify this table by hand.
In this case, for each of the four actions, we must compute a transition probability from
each of the five possible starting rooms to each of the five possible destination rooms:
<span class="math notranslate nohighlight">\(4*5*5=100\)</span> entries.
In the example above, impossible transitions (e.g., moving up from the living room to any other room)
are assigned zero probability.
Other actions are assumed to have 80% chance of success (e.g., moving right from the living room
and arriving to the kitchen is assigned a transition probability of <span class="math notranslate nohighlight">\(0.8\)</span>).</p>
<p>Conditional probability distributions do not <em>have</em> to be specified as giant
tables. Because the state space is potentially quite large, such a
motion model is almost never explicitly specified, but
rather exploits the semantics of the states and actions to calculate the conditional distribution at run-time.
For example, rather than enumerate every possible action from every possible room, we might
determine the probability of successfully moving to an adjacent room is <span class="math notranslate nohighlight">\(0.8\)</span>, for all
rooms and for all actions, and that the probability of failing to do so is <span class="math notranslate nohighlight">\(0.2\)</span>.
If we apply this rule to each combination of action and adjacent rooms, we can
construct specific rows the table above on an as-needed basis.</p>
<div class="section" id="exercises">
<h3><span class="section-number">3.2.2.1. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Even though the CPT above
has 100 numbers in it, how many independent degrees of freedom do we
actually have when specifying this CPT?</p></li>
<li><p>Specify a <em>parametric</em> conditional density for the action models for
the vacuuming robot that is somewhat realistic, yet not completely
deterministic.</p></li>
<li><p>It is possible to create models that do not reflect everyday
physics. For example, how could we model the game “Portal”?</p></li>
</ol>
</div>
</div>
<div class="section" id="computing-the-posterior-distribution-for-a-sequence-of-actions">
<h2><span class="section-number">3.2.3. </span>Computing the Posterior Distribution for a Sequence of Actions<a class="headerlink" href="#computing-the-posterior-distribution-for-a-sequence-of-actions" title="Permalink to this headline">¶</a></h2>
<p>Suppose we apply a sequence of actions <span class="math notranslate nohighlight">\(a_1 \dots a_t\)</span>
and we wish to compute the probability distribution associated to the resulting state <span class="math notranslate nohighlight">\(X_{t+1}\)</span>?
We can accomplish this by applying the law of total probability and conditioning each
term on the applied action <span class="math notranslate nohighlight">\(a_1\)</span>.
First, recall the law of total probability:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(X_{t+1} = x_{t+1} ) = \sum_{x_t} P(X_{t+1} | X_t = x_t) P(X_t = x_t) \\
\end{split}\]</div>
<p>Now, condition every term in the above equation on the sequence of actions
<span class="math notranslate nohighlight">\(a_1 \dots a_t\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(X_{t+1} = x_{t+1} | a_1 \dots a_t) = \sum_{x_t} P(X_{t+1} | X_t = x_t, a_1 \dots a_t) P(X_t = x_t |a_1 \dots a_t) \\
\end{split}\]</div>
<p>This expression may seem complex, but it can be simplified by making the following observation:
<em>If we know that the robot is in a specific state <span class="math notranslate nohighlight">\(x_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>, then the next state will depend only
on the action executed at time <span class="math notranslate nohighlight">\(t\)</span>; the previously executed actions will not affect our belief
about <span class="math notranslate nohighlight">\(X_{t+1}\)</span>.</em>  For example, if the robot executes the action <em>move down</em> knowing with certainty that it is in the living room at time <span class="math notranslate nohighlight">\(t\)</span>,
the sequence of actions that brought the robot to the living room (i.e., actions <span class="math notranslate nohighlight">\(a_1 \dots a_{t-1}\)</span>) do not affect our belief
about whether the robot will arrive to the hallway.
Mathematically, we can write this relationship as follows:</p>
<div class="math notranslate nohighlight">
\[ P(X_{t+1} | X_t = x_t, a_1 \dots a_t) =  P(X_{t+1} | X_t = x_t,  a_t) \]</div>
<p>We can also  simplify the term <span class="math notranslate nohighlight">\(P(X_t = x_t |a_1 \dots a_t)\)</span>.
Notice that the action performed at time <span class="math notranslate nohighlight">\(t\)</span> has no affect on the state at time <span class="math notranslate nohighlight">\(t\)</span>.
For example, if the robot executes the <em>move down</em> action
in the living room at time <span class="math notranslate nohighlight">\(t\)</span>, this actions does not change the fact that the robot was in the living room
at time <em>t</em>.
Therefore, we have</p>
<div class="math notranslate nohighlight">
\[ P(X_t = x_t |a_1 \dots a_t) =  P(X_t = x_t |a_1 \dots a_{t-1})\]</div>
<p>Applying these two simplifications, we obtain the final form for our posterior:
$<span class="math notranslate nohighlight">\(
P(X_{t+1} = x_{t+1} | a_1 \dots a_t) = \sum_{x_t} P(X_{t+1} | X_t = x_t, a_t) P(X_t = x_t |a_1 \dots a_{t-1}) \\
\)</span>$</p>
<p>We can think of the terms in this expression as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(X_{t+1} = x_{t+1} | a_1 \dots a_t)\)</span> is the posterior</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_{t+1} | X_t = x_t, a_t)\)</span> is the motion model</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_t = x_t |a_1 \dots a_{t-1})\)</span> is the prior.</p></li>
</ul>
<p>For the initial state, when <span class="math notranslate nohighlight">\(t=0\)</span>, no actions have yet been applied, and the prior is merely
the probability distribution at the initial state <span class="math notranslate nohighlight">\(P(X_1 = x_1)\)</span>.
Specifically, we can compute the posterior at time <span class="math notranslate nohighlight">\(t=2\)</span> by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(X_{2} = x_{2} | a_1 ) = \sum_{x_1} P(X_{2} | X_1 = x_1, a_1) P(X_1 = x_1 ) \\
\end{split}\]</div>
</div>
<div class="section" id="state-transition-matrices-and-the-belief-state">
<h2><span class="section-number">3.2.4. </span>State Transition Matrices and the Belief State<a class="headerlink" href="#state-transition-matrices-and-the-belief-state" title="Permalink to this headline">¶</a></h2>
<p>In order to specify the complete posterior distribution at time <span class="math notranslate nohighlight">\(t+1\)</span>, we would need to perform the calculation above
five times, once for each of the possible next states (<span class="math notranslate nohighlight">\(L,K,O,H,D\)</span>).
This complete distribution is called the belief state, defined as</p>
<div class="math notranslate nohighlight">
\[b_{t+1} = \left[ P(X_{t+1} = L | a_1, \dots a_t),
P(X_{t+1} = K | a_1, \dots a_t),
P(X_{t+1} = O | a_1, \dots a_t),
P(X_{t+1} = H | a_1, \dots a_t),
P(X_{t+1} = D | a_1, \dots a_t) \right]
\]</div>
<p>We can write the equations for the belief state in a compact form by writing the conditional probability tables as
transition matrices.
To do so, for each action, we merely gather the corresponding rows from the complete conditional probability
table into a state transition matrix.
For the action <em>move right</em>, this is illustrated below in
Figure <a href="#fig:Vacuum" data-reference-type="ref" data-reference="fig:TM">4</a>.</p>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures3/S32-transition-matrix.png?raw=1" id="fig:TM" style="width:20cm" alt="" />
<figcaption id="fig:TM" label="fig:TM">The transition matrix for the action *move right*.
</figcaption>
</figure>
<p>If we apply the action <em>move right</em> to the initial state, by straightforward calculations, we can see that <span class="math notranslate nohighlight">\(b_2 = b_1 M_r\)</span>.
This can be generalized to a sequence of actions.
If we execute action <span class="math notranslate nohighlight">\({\cal A}_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>,
the belief state <span class="math notranslate nohighlight">\(b_{t+1}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[b_{t+1} = b_t M_{{\cal A}_t}\]</div>
<p>in which <span class="math notranslate nohighlight">\(M_{\cal A}\)</span>
the conditional probability matrix for action <span class="math notranslate nohighlight">\(\cal A\)</span> and <span class="math notranslate nohighlight">\(b_t\)</span> is the
belief state at time <span class="math notranslate nohighlight">\(t\)</span>.
We refer to this equation as a <em>belief transition function</em> – given the
belief at time <span class="math notranslate nohighlight">\(t\)</span> and the action <span class="math notranslate nohighlight">\(a_t\)</span>, it can be applied to compute the belief at time <span class="math notranslate nohighlight">\(t+1\)</span>.
This result can be applied recursively to yield</p>
<div class="math notranslate nohighlight">
\[b_{t+1} = b_1 M_{{\cal A}_1} \dots M_{{\cal A}_t}\]</div>
</div>
<div class="section" id="controlled-markov-chains">
<h2><span class="section-number">3.2.5. </span>Controlled Markov Chains<a class="headerlink" href="#controlled-markov-chains" title="Permalink to this headline">¶</a></h2>
<p>In the derivation above of the belief transition function we employed a temporal decoupling property,
namely, given the state at time <span class="math notranslate nohighlight">\(t\)</span>, all actions that were applied prior to time <span class="math notranslate nohighlight">\(t\)</span> were irrelevant
to determining the belief state <span class="math notranslate nohighlight">\(b_{t+1}\)</span>.
This is an example of what is called <strong>the Markov property</strong>.
Variations of this property
are essential for reducing the amount of computation required to reason probabilistically over long periods of time.</p>
<p>The most common example of this property arises in systems that are called <strong>Markov chains</strong>.
In its simplest form, a Markov chain is a sequence of random variables, <span class="math notranslate nohighlight">\(X_1, X_2, \dots \)</span>
for which</p>
<div class="math notranslate nohighlight">
\[P(X_{t+1} | X_1 \dots X_t) = P(X_{t+1} | X_t)\]</div>
<p>For Markov chains, knowing <span class="math notranslate nohighlight">\(X_t\)</span> completely decouples the past (i.e., <span class="math notranslate nohighlight">\(X_1 \dots X_{t-1}\)</span>) from the future (i.e., <span class="math notranslate nohighlight">\(X_{t+1}\)</span>).
Therefore, when reasoning about future states, we need not perform computations over the entire
history of the system; if we know <span class="math notranslate nohighlight">\(X_t\)</span>, we need only perform computations related to the present
when reasoning about the future.</p>
<p>Markov chains have a nice graphical representation.
Each node corresponds to a random variable,
and directed edges specify conditional probabilities.
As an application, we can use this simple graphical model to represent
the probabilistic transitions between states, as shown below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">)</span> <span class="c1">## states for times 1...N</span>
<span class="n">markov_chain</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">markov_chain</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">markov_chain</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="s2">&quot;6/1/1/1/1 1/6/1/1/1 1/1/6/1/1 1/1/6/1/1 1/1/1/1/6 &quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">markov_chain</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S32_vacuum_actions_19_0.svg" src="_images/S32_vacuum_actions_19_0.svg" /></div>
</div>
<p>Each node in this graph denotes a random variable, and therefore each node has an associated probability distribution.
If we know the distribution for the initial state <span class="math notranslate nohighlight">\(X_1\)</span>, we can iteratively compute the distributions for
<span class="math notranslate nohighlight">\(X_k\)</span> for all <span class="math notranslate nohighlight">\(k &gt; 1\)</span> by evaluating the conditional distributions associated to the directed edges in the graph.</p>
<p>Our robot vacuum cleaner is slightly more sophisticated than this simple Markov chain, since
the robot has the ability to execute actions, and these actions affect the propagation
of probabilities through the chain.
This type of system is sometimes called a <strong>controlled Markov chain</strong>, since it incorporates
a control input (the actions) into the usual Markov chain.</p>
<p>Graphically, we can represent such a system by augmenting the graph above to include nodes that denote actions.
We use a <em>box</em> to denote nodes whose values are known.
Since the robot knows which actions it will execute, action nodes are denoted by boxes.
For our vacuuming robot, we also know the value of the initial state,
since robot always begins in the office.
Therefore, we also use a box to denote the initial state in this graph.</p>
<p>As an example, the code below builds the controlled Markov chain for our system up to time <span class="math notranslate nohighlight">\(t=2\)</span>.
By applying the belief transition equation above, we can compute the probabililty distribution for <span class="math notranslate nohighlight">\(X_2\)</span>,
since the action <span class="math notranslate nohighlight">\(a_1\)</span> and the initial state <span class="math notranslate nohighlight">\(X_1\)</span> are both completely known.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">action_prior</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteDistribution</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;1/1/1/1&quot;</span><span class="p">)</span>
<span class="n">fragment</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">fragment</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">motion_model</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">fragment</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S32_vacuum_actions_24_0.svg" src="_images/S32_vacuum_actions_24_0.svg" /></div>
</div>
<p>For the specific example of</p>
<p>Given values for the parent variables, we can examine the corresponding transition probability. For example, if we start from the <span class="math notranslate nohighlight">\(X_1=\text{Office}\)</span> and attempt to go right, i.e., action <span class="math notranslate nohighlight">\(A_0=\text{R}\)</span>, we retrieve the following PMF over the next state <span class="math notranslate nohighlight">\(X_2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="s2">&quot;Office&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="s2">&quot;R&quot;</span><span class="p">})</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">motion_model</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(X2):</i></p>
<div>
<table class='DecisionTreeFactor'>
  <thead>
    <tr><th>X2</th><th>value</th></tr>
  </thead>
  <tbody>
    <tr><th>Living Room</th><td>0</td></tr>
    <tr><th>Kitchen</th><td>0</td></tr>
    <tr><th>Office</th><td>0.2</td></tr>
    <tr><th>Hallway</th><td>0.8</td></tr>
    <tr><th>Dining Room</th><td>0</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>This idea can be extended to arbitrarily many actions by merely adding action and state nodes for each
time <span class="math notranslate nohighlight">\(t\)</span>. The code below creates a controlled Markov chain with three states.
Try varying the value of <span class="math notranslate nohighlight">\(N\)</span> to see other examples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span> <span class="c1"># actions for times 1...N-1</span>
<span class="n">bayesNet</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">bayesNet</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">bayesNet</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span> <span class="c1"># add creates conditional and adds</span>
<span class="n">show</span><span class="p">(</span><span class="n">bayesNet</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S32_vacuum_actions_28_0.svg" src="_images/S32_vacuum_actions_28_0.svg" /></div>
</div>
</div>
<div class="section" id="forward-simulation">
<h2><span class="section-number">3.2.6. </span>Forward Simulation<a class="headerlink" href="#forward-simulation" title="Permalink to this headline">¶</a></h2>
<p>We can use simulation in a graphical model to explore what a sequence of
actions will yield as outcome.
To sample from a <em>conditional</em> distribution <span class="math notranslate nohighlight">\(p(X|Y)\)</span> we need to make
sure we sample the variable <span class="math notranslate nohighlight">\(Y\)</span> beforehand, and then proceed simply by
selecting the appropriate PMF depending on the value of <span class="math notranslate nohighlight">\(Y\)</span>. We can then
proceed as before using the inverse transform sampling method.</p>
<p>Forward sampling in a Markov chain simply repeats these steps in
succession, proceeding from left to right.
Simulating a robot <em>given</em> an initial state <span class="math notranslate nohighlight">\(X_1\)</span> and
sequence of actions <span class="math notranslate nohighlight">\(A_{1},A_{2},\ldots\)</span> is then equivalent to sampling
from this Markov chain:</p>
<ol>
<li><p>Set <span class="math notranslate nohighlight">\(k=1\)</span>.</p></li>
<li><p>Simulate the effect of the next action by sampling the next state
<span class="math notranslate nohighlight">\(x_{k+1}\)</span> from</p>
<div class="math notranslate nohighlight">
\[P(X_{k+1}|X_{k}=x_{k},A_{k}=a_{k}).\]</div>
</li>
<li><p>Increase <span class="math notranslate nohighlight">\(k\)</span> and return to step <span class="math notranslate nohighlight">\(2\)</span>.</p></li>
</ol>
<p>Below we show how to code this up and show  4 different “rollouts” by simulating in this way. After
that, we can approximate the PMF of the final state by construction a
histogram over the possible values of the state:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">a1</span><span class="p">,</span> <span class="n">a2</span><span class="p">):</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="n">x1</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">a1</span><span class="p">})</span> <span class="c1"># initial state and action</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">[</span><span class="n">bayesNet</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">assignment</span><span class="p">({</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span><span class="n">x2</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">a2</span><span class="p">})</span> <span class="c1"># next state and action</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">rooms</span><span class="p">[</span><span class="n">bayesNet</span><span class="o">.</span><span class="n">at</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;Office&quot;</span><span class="p">,</span> <span class="s2">&quot;R&quot;</span><span class="p">,</span><span class="s2">&quot;U&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Office&#39;, &#39;Office&#39;, &#39;Office&#39;]
[&#39;Office&#39;, &#39;Hallway&#39;, &#39;Hallway&#39;]
[&#39;Office&#39;, &#39;Hallway&#39;, &#39;Living Room&#39;]
[&#39;Office&#39;, &#39;Office&#39;, &#39;Office&#39;]
</pre></div>
</div>
</div>
</div>
<p>While simple, simulating from a forward model is a rather important
technique, and underlies some of the recent successes in deep
reinforcement learning, as well as the success of DeepMind in beating
the world’s best players of the game of Go.</p>
<div class="section" id="exercise">
<h3><span class="section-number">3.2.6.1. </span>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h3>
<p>Generalize the above forward sampling algorithm to an arbitrary number of actions. Hint: you will have to make sure the variables are defined, and the Bayes Net is extended properly.</p>
</div>
</div>
<div class="section" id="bayes-nets">
<h2><span class="section-number">3.2.7. </span>Bayes Nets<a class="headerlink" href="#bayes-nets" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>Bayes nets provide a graphical language to string together conditional probabilities into a generative world model.</p>
</div></blockquote>
<p>A Markov chain is a special case of the more general <strong>Bayes network</strong>.
A Bayes net is a directed <em>acyclic</em> graph (DAG) describing a factored
probability distribution a set of random variables.
The joint distribution on the set of all variables is given as</p>
<div class="math notranslate nohighlight">
\[P(\{X_{i}\})=\prod_{i=1}^{n}P(X_{i}|\Pi_{i})\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the number
of variables, and <span class="math notranslate nohighlight">\(\Pi_{i}\)</span> denotes the set of parents for variable
<span class="math notranslate nohighlight">\(X_{i}\)</span>. An example of a Bayes net is shown in the Figure below,
and it is simply a graphical representation of which random variables’s
CPT depend on which other variables. In this case, the joint
distribution can be read off as</p>
<div class="math notranslate nohighlight">
\[P(W,X,Y,Z)=P(W|X,Z)P(X|Y,Z)P(Y|Z)P(Z).\]</div>
<p>Note that the order in which
we multiply the conditionals does not matter, but we typically prefer to put the parents more towards the right, as above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wxyz</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">W1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;W&quot;</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
<span class="n">Z1</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="p">[</span><span class="n">X1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="p">[</span><span class="n">Y1</span><span class="p">,</span> <span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1 1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Y1</span><span class="p">,</span> <span class="p">[</span><span class="n">Z1</span><span class="p">],</span> <span class="s2">&quot;1/1 1/1&quot;</span><span class="p">)</span>
<span class="n">wxyz</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Z1</span><span class="p">,</span> <span class="s2">&quot;1/1&quot;</span><span class="p">)</span>
<span class="n">show</span><span class="p">(</span><span class="n">wxyz</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S32_vacuum_actions_34_0.svg" src="_images/S32_vacuum_actions_34_0.svg" /></div>
</div>
<p>Note that the above graph has cycles, but the cycles are only in the underlying <em>undirected</em> graph, not in the directed graph. Directed cycles, i.e. cycles with a consistent direction, are not allowed.</p>
<p>A Bayes net can be a very efficient representation of complex
probability distributions, as they encode the dependence and especially
independence relationships between the variables.
The Bayes net above was created assuming binary variables, and hence did not take
a lot of effort to specify, but as we saw above, even for relatively small state spaces
the complexity of specifying CPTs can be daunting.</p>
<p>For example, if we
were to construct a full table of probabilities for each possible
outcome of the variables <span class="math notranslate nohighlight">\(W\)</span>,<span class="math notranslate nohighlight">\(X\)</span>,<span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span>, the table could be quite
long. For example, if we assume they all have 10 possible values, then
the full joint has <span class="math notranslate nohighlight">\(10^{4}\)</span> entries, i.e., <span class="math notranslate nohighlight">\(10,000\)</span> unique values. You
can save a tiny bit, because they have to sum up to 1, so strictly
speaking we need only <span class="math notranslate nohighlight">\(9,999\)</span> values. In contrast, we can tally how many
entries all four CPT tables have for the Bayes net above.
In the table below we did just that:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>CPT</p></th>
<th class="head"><p># entries</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><em>P(Z)</em></p></td>
<td><p>9</p></td>
</tr>
<tr class="row-odd"><td><p><em>P(Y|Z)</em></p></td>
<td><p>90</p></td>
</tr>
<tr class="row-even"><td><p><em>P(X|Y,Z)</em></p></td>
<td><p>900</p></td>
</tr>
<tr class="row-odd"><td><p><em>P(W|X,Z)</em></p></td>
<td><p>900</p></td>
</tr>
</tbody>
</table>
<p>For example, <span class="math notranslate nohighlight">\(P(X|Y,Z)\)</span> has 900 entries, i.e., 9
(independent) entries for each of 100 possible combinations of <span class="math notranslate nohighlight">\(Y\)</span> and
<span class="math notranslate nohighlight">\(Z\)</span>. Hence, the total number of parameters we need is only <span class="math notranslate nohighlight">\(1,899\)</span>,
which is way less than <span class="math notranslate nohighlight">\(9,999\)</span>.</p>
</div>
<div class="section" id="factored-state-representations">
<h2><span class="section-number">3.2.8. </span>Factored State Representations<a class="headerlink" href="#factored-state-representations" title="Permalink to this headline">¶</a></h2>
<p>Factored state representations are useful if the state of the robot can
be described using features that are relatively independent of each
other. Continuing our example, the robot vacuum cleaner might also run
out of battery power, so we could associate a different variable with
its battery status, e.g., <code class="docutils literal notranslate"><span class="pre">empty</span></code>, <code class="docutils literal notranslate"><span class="pre">half</span></code>, or <code class="docutils literal notranslate"><span class="pre">full</span></code>.
The state of the robot would then be specified by the combination of
two variables: the room the robot is in, and its battery status.
Note that now the total number of possible states
is combinatorial: if there are five rooms and three different battery
levels, we have a total of 15 possible states for the robot.</p>
<p>A possible model for battery life could be the following transition table, which is independent of which action was taken, and will always progress from <code class="docutils literal notranslate"><span class="pre">full</span></code> to <code class="docutils literal notranslate"><span class="pre">half</span></code>, then from <code class="docutils literal notranslate"><span class="pre">half</span></code> to <code class="docutils literal notranslate"><span class="pre">empty</span></code>, and of course once the battery is empty it will stay empty:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">battery_states</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;full&quot;</span><span class="p">,</span> <span class="s2">&quot;half&quot;</span><span class="p">,</span> <span class="s2">&quot;empty&quot;</span><span class="p">]</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">VARIABLES</span><span class="o">.</span><span class="n">discrete_series</span><span class="p">(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">battery_states</span><span class="p">)</span>
<span class="n">spec_b</span> <span class="o">=</span> <span class="s2">&quot;9/1/0 0/9/1 0/0/1 &quot;</span>
<span class="n">pretty</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">spec_b</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(B2|B1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>B1</i></th><th>full</th><th>half</th><th>empty</th></tr>
  </thead>
  <tbody>
    <tr><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The graphical model approach allows us to easily extend probabilistic
actions to factored state representations. The code below shows one way to do it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">factored</span> <span class="o">=</span> <span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteBayesNet</span><span class="p">()</span>
<span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state_prior</span><span class="p">)</span>
<span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[],</span> <span class="s2">&quot;1/0/0&quot;</span><span class="p">)</span> <span class="c1"># initial battery state</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="n">vacuum</span><span class="o">.</span><span class="n">action_spec</span><span class="p">)</span> <span class="c1"># motion model for location</span>
    <span class="n">factored</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">))</span> <span class="c1"># battery evolution model</span>
<span class="n">show</span><span class="p">(</span><span class="n">factored</span><span class="p">,</span> <span class="n">hints</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;A&quot;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">},</span> <span class="n">boxes</span><span class="o">=</span><span class="p">{</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/S32_vacuum_actions_40_0.svg" src="_images/S32_vacuum_actions_40_0.svg" /></div>
</div>
<p>You can see that under the transition models chosen, there are now two semi-independent Markov chains. In fact, as the action sequence is <em>given</em>, the chains are truly independent.</p>
<div class="section" id="id1">
<h3><span class="section-number">3.2.8.1. </span>Exercise<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Note that  do you above model makes a number of strong statements about the nature of the worlds:</p>
<ol class="simple">
<li><p>The next battery state does not depend on where we are in the world. This seems like an OK assumption. Still, can you think of situations where this is not a realistic assumptions?</p></li>
<li><p>The next state does not depend on the battery life. Maybe this is not so defensible: clearly, if the battery is empty the robot cannot move, and the next state is the same as the previous state. It is worthwhile to think about what you would change above to make a more realistic model of the world.</p></li>
</ol>
</div>
</div>
<div class="section" id="gtsam-101">
<h2><span class="section-number">3.2.9. </span>GTSAM 101<a class="headerlink" href="#gtsam-101" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>The GTSAM concepts used in this section, explained.</p>
</div></blockquote>
<p>Above, we use the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteBayesNet</span></code> class, and in particular these methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add(self:,</span> <span class="pre">key:</span> <span class="pre">Tuple[int,</span> <span class="pre">int],</span> <span class="pre">parents:</span> <span class="pre">List[Tuple[int,</span> <span class="pre">int]],</span> <span class="pre">spec:</span> <span class="pre">str)</span> <span class="pre">-&gt;</span> <span class="pre">None</span></code>: adds a conditional with the same arguments as the <code class="docutils literal notranslate"><span class="pre">gtsam.DiscreteConditional</span></code> constructor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">at(self,</span> <span class="pre">i:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">gtsam.DiscreteConditional</span></code>: retrieves the <span class="math notranslate nohighlight">\(i^{th}\)</span> conditional added.</p></li>
</ul>
<p>We used a sleight of hand above to extend the battery depletion model to depend on the navigation action. The following is a but of python code that replicates our specification four times:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 9/1/0 0/9/1 0/0/1 &#39;
</pre></div>
</div>
</div>
</div>
<p>We then made sure to specify the action <em>before</em> the previous battery state, so that the string above works out. Below we pretty-print to make verify this came out right:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretty</span><span class="p">(</span><span class="n">gtsam</span><span class="o">.</span><span class="n">DiscreteConditional</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">spec_b</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<p>  <i>P(B2|A2,B1):</i></p>
<table class='DiscreteConditional'>
  <thead>
    <tr><th><i>A2</i></th><th><i>B1</i></th><th>full</th><th>half</th><th>empty</th></tr>
  </thead>
  <tbody>
    <tr><th>L</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>L</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>L</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>R</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>R</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>R</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>U</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>U</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>U</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
    <tr><th>D</th><th>full</th><td>0.9</td><td>0.1</td><td>0</td></tr>
    <tr><th>D</th><th>half</th><td>0</td><td>0.9</td><td>0.1</td></tr>
    <tr><th>D</th><th>empty</th><td>0</td><td>0</td><td>1</td></tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Of course, it is entirely possible to make the battery model <em>dependent</em> on the action chosen.</p>
<p>Finally, a word about the graphs above. You might wonder, why these graphs come out so beautifully positioned, e.g., to indicate time from left to right. This was accomplished with the <code class="docutils literal notranslate"><span class="pre">hints</span></code> argument, which positions variables series at an appropriate height. Similarly, the <code class="docutils literal notranslate"><span class="pre">boxes</span></code> argument (which takes <code class="docutils literal notranslate"><span class="pre">gtsam.Keys</span></code>, not tuples) indicates which variables should considered as given.</p>
<p>These arguments are handled in the <a class="reference external" href="https://gtbook.github.io/gtbook/"><code class="docutils literal notranslate"><span class="pre">gtbook</span></code> library</a>, and are passed on in the appropriate format to the underlying GTSAM <code class="docutils literal notranslate"><span class="pre">dot</span></code> methods.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="S31_vacuum_state.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3.1. </span>Modeling the State of the Vacuum Cleaning Robot</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="S33_vacuum_sensing.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.3. </span>Dynamic Bayes Nets</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Frank Dellaert and Seth Hutchinson<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>