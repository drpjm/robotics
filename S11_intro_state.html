
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1.1. Representing State &#8212; Introduction to Robotics and Perception</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="1.2. Robot Actions" href="S12_intro_actions.html" />
    <link rel="prev" title="1. Introduction" href="S10_introduction.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-312077-7', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Robotics and Perception</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction to Robotics and Perception
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="S10_introduction.html">
   1. Introduction
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     1.1. Representing State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S12_intro_actions.html">
     1.2. Robot Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S13_intro_sensing.html">
     1.3. Sensing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S14_intro_perception.html">
     1.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S15_intro_decision.html">
     1.5. Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S16_intro_learning.html">
     1.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S20_sorter_intro.html">
   2. A Trash Sorting Robot
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S21_sorter_state.html">
     2.1. Modeling the World State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S22_sorter_actions.html">
     2.2. Actions for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S23_sorter_sensing.html">
     2.3. Sensors for Sorting Trash
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S24_sorter_perception.html">
     2.4. Perception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S25_sorter_decision_theory.html">
     2.5. Decision Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S26_sorter_learning.html">
     2.6. Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S30_vacuum_intro.html">
   3. A Robot Vacuum Cleaner
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S31_vacuum_state.html">
     3.1. Modeling the State of the Vacuum Cleaning Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S32_vacuum_actions.html">
     3.2. Actions over time
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S33_vacuum_sensing.html">
     3.3. Dynamic Bayes Nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S34_vacuum_perception.html">
     3.4. Perception with Graphical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S35_vacuum_decision.html">
     3.5. Markov Decision Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S36_vacuum_RL.html">
     3.6. Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S40_logistics_intro.html">
   4. Warehouse Robots in 2D
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S41_logistics_state.html">
     4.1. Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S42_logistics_actions.html">
     4.2. Moving in 2D
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S43_logistics_sensing.html">
     4.3. Sensor Models with Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S44_logistics_perception.html">
     4.4. Localization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S45_logistics_planning.html">
     4.5. Planning for Logistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S46_logistics_learning.html">
     4.6. Some System Identification
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S50_diffdrive_intro.html">
   5. A Mobile Robot With Simple Kinematics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S51_diffdrive_state.html">
     5.1. State Space for a Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S52_diffdrive_actions.html">
     5.2. Motion Model for the Differential Drive Robot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S53_diffdrive_sensing.html">
     5.3. Robot Vision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S54_diffdrive_perception.html">
     5.4. Computer Vision 101
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S55_diffdrive_planning.html">
     5.5. Path Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S56_diffdrive_learning.html">
     5.6. Deep Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S60_driving_intro.html">
   6. Autonomous Vehicles
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S61_driving_state.html">
     6.1. Planar Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S62_driving_actions.html">
     6.2. Kinematics for Driving
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S63_driving_sensing.html">
     6.3. Sensing for Autonomous Vehicles
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S64_driving_perception.html">
     6.4. SLAM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S65_driving_planning.html">
     6.5. Planning for Autonomous Driving.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S66_driving_DRL.html">
     6.6. Deep Reinforcement Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="S70_drone_intro.html">
   7. Autonomous Drones in 3D
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="S71_drone_state.html">
     7.1. Moving in Three Dimensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S72_drone_actions.html">
     7.2. Multi-rotor Aircraft
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S73_drone_sensing.html">
     7.3. Sensing for Drones
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S74_drone_perception.html">
     7.4. Visual SLAM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="S75_drone_planning.html">
     7.5. Trajectory Optimization
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/S11_intro_state.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/gtbook/robotics"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/gtbook/robotics/issues/new?title=Issue%20on%20page%20%2FS11_intro_state.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/gtbook/robotics/main?urlpath=tree/S11_intro_state.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representing-the-world-state">
   1.1.1. Representing the World State
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representing-the-robot-s-state">
   1.1.2. Representing the Robot’s State
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Representing State</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representing-the-world-state">
   1.1.1. Representing the World State
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#representing-the-robot-s-state">
   1.1.2. Representing the Robot’s State
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><a href="https://colab.research.google.com/github/gtbook/robotics/blob/main/S11_intro_state.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="tex2jax_ignore mathjax_ignore section" id="representing-state">
<h1><span class="section-number">1.1. </span>Representing State<a class="headerlink" href="#representing-state" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>Choosing the right representation for state is key to effective reasoning about the effects of actions in the world.</p>
</div></blockquote>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<div align='center'>
<img src='https://github.com/gtbook/robotics/blob/main/Art/steampunk/S11-Robot%20menagerie-03.jpg?raw=1' style='height:256 width:100%'/>
</div>
</div></div>
</div>
<p>In order to reason about the world and about its own actions in the
world, a robot requires some sort of representations of both itself, and
the the world that it inhabits. For any specific robotic system, the
system designer must decide what to represent, and which
representational scheme should be used. Furthermore, different
representation schemes might be used for different aspects of a
particular problem. For example, if a robot house keeper is charged with
doing the laundry, reasoning about moving from the bedroom to the
laundry room versus reasoning about folding the laundry would require
fundamentally different types of representations. For the former, a
high-level description of the layout of rooms in the house might
suffice, while for the latter, the robot might need to model articles of
clothing as nonrigid, deformable objects.
In the chapters that follow,
we will explore a variety of representational schemes, ranging from
high-level, discrete abstractions to low-level continuous
representations.</p>
<div class="section" id="representing-the-world-state">
<h2><span class="section-number">1.1.1. </span>Representing the World State<a class="headerlink" href="#representing-the-world-state" title="Permalink to this headline">¶</a></h2>
<p>The robot’s information about its environment is generally referred to
as the <em>world state</em>. For a chess playing robot, this might include a
complete list of the positions of all chess pieces on the board. For a
house-keeping robot, the world state might include a map of the house,
locations of furniture, and locations of various household objects. In
both cases, the world state excludes many details about the world that
are not directly relevant to the robot’s objectives. For example, a
house-keeping robot might not need to know the colors of the walls, the
thermostat setting for the bedroom, or the titles of books on a shelf.
The key idea of <em>world state</em> is that it should include the information
necessary for the robot to understand the environment well enough to
successfully perform its tasks.</p>
<p>How to represent the world state depends on the kind of information that
is required. High-level, symbolic representations are often sufficient
for the purpose of constructing general robot plans. A classical example
is the STRIPS system for robot planning in a simple <em>blocks world</em>.
Figure
<a href="#fig:blocks-world" data-reference-type="ref" data-reference="fig:blocks-world">1</a>
shows a simple example. In STRIPS, the state of the world is represented
by symbolic relations, such as those shown in Figure
<a href="#fig:blocks-world" data-reference-type="ref" data-reference="fig:blocks-world">1</a>b.
This simple set of relations tells us that Blocks A and C are resting on
the table, that Block B rests on the top of Block A, and that nothing
rests atop either Block B or Block C. Equipped with such a description,
STRIPS can create plans, for example, to place Block A atop Block C by
picking up Block B and placing it on the table, then picking up Block A
and placing it atop block C. This plan excludes any geometric
description of how to perform the task, but it provides a high-level
description of the sub-tasks that the robot must execute to accomplish
its end goal. In later chapters, we will see how this kind of planning
works in detail.</p>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures1/blocks-world.jpg?raw=1" title="fig:" id="fig:blocks-world" style="width:12.5cm" alt=""/>
<figcaption>An example from the Blocks World. (a) A simple blocks world scene. (b) The symbolic description of the world state.
</figcaption>
</figure>
<p>While this kind of high-level, qualitative state description may be
useful for task-level planning, because it fails to capture any of the
geometric aspects of the environment, it would be insufficient when the
robot begins to actually move in, and interact with, its environment.
For mobile robots, it is often sufficient to use a discrete grid to
represent which parts of the environment contain objects, and thus
cannot be traversed by the robot. Because such objects impede the
ability of the robot to move freely, we typically refer to these as
<em>obstacles</em>. The prototypical path planning problem in robotics is to
find a path for the robot from its initial location to a specified goal
location, while avoiding collision with any obstacles in the
environment. Figure
<a href="#fig:chap1-occupancy-grid" data-reference-type="ref" data-reference="fig:chap1-occupancy-grid">2</a>(a)
shows an example of an <em>occupancy grid</em>, a grid-based map that
explicitly indicates which grid cells are occupied by obstacles. If we
assume that the robot is able to move to any adjacent empty grid cell
that is directly above, below, left, or right of its current location,
planning can be accomplished using graph search methods. Figure
<a href="#fig:chap1-occupancy-grid" data-reference-type="ref" data-reference="fig:chap1-occupancy-grid">2</a>(b)
illustrates a path in the occupancy grid. In later chapters we will
describe how to build an occupancy-grid map from sensor data, how the
robot can determine its location in the map, how graph search algorithms
can be used to construct a path from start to goal, and how the robot
can execute this plan to navigate in its environment.</p>
<figure>
<div class="row">
  <div class="column">
    <img src="https://github.com/gtbook/robotics/blob/main/Figures1/occupancy-grid.jpg?raw=1" title="fig:" id="fig:chap1-occupancy-grid" style="width:5.5cm" alt="" />
    <p class="center">(a)</p>
  </div>
  <div class="column">
    <img src="https://github.com/gtbook/robotics/blob/main/Figures1/occupancy-grid-plan.jpg?raw=1" title="fig:" id="fig:chap1-occupancy-grid" style="width:5.5cm" alt="" />
    <p class="center">(b)</p>
  </div>
</div>
<figcaption>Using an occupancy grid to represent the environment of a mobile robot. (a) Shaded cells are occupied by obstacles. (b) A plan to move from the initial to goal cell in the occupancy grid. 
</figcaption>
</figure>
<p>In some cases, for example if task requires manipulating objects in the
environment, a more precise geometric description of the state may be
required. Suppose, for example, that a chess playing robot wishes to
move its king. In this case, for the robot to grasp the king, its
precise location must be known. There are several ways to represent this
kind of geometric information, but the most common is to define a
Cartesian coordinate frame that is <em>rigidly attached</em> to the king. This
merely means that the relationship between the king and this coordinate
frame is fixed, and does not change when the king is moved. One such
possible assignment is shown in Figure
<a href="#fig:chap1-king-frame" data-reference-type="ref" data-reference="fig:chap1-king-frame">3</a>.
In order to grasp the king, the robot would perform appropriate
geometric computations to bring its fingers to specific positions
relative to this coordinate frame. This requires, of course, knowing the
precise position and orientation of the king’s coordinate frame relative
to the robot, information that can be obtained using the robot’s
sensors. In later chapters, we will describe in detail the geometric
computations required for this kind of task, as well as how sensors can
be used to determine relevant geometric aspects of the world, including
the positions and orientations of objects in the robot’s work space.</p>
<figure>
<div class="row">
  <div class="column">
    <img src="https://github.com/gtbook/robotics/blob/main/Figures1/king-frame.jpg?raw=1" title="fig:" id="fig:chap1-king-frame" style="height:9cm" alt="" />
    <p class="center">(a)</p>
  </div>
  <div class="column">
    <img src="https://github.com/gtbook/robotics/blob/main/Figures1/king-frame-rotated.jpg?raw=1" title="fig:" id="fig:chap1-king-frame" style="height:9cm" alt="" />
    <p class="center">(b)</p>
  </div>
</div>
<figcaption>A chess piece with an attached Cartesian coordinate frame. (a) The frame origin is located at the center of the cross, the z-axis is aligned with the main axis of the body, and the y-axis lies in the plane containing the cross. The x-axis completes a right-handed coordinate frame (b) The frame is rigidly attached to the chess piece, and moves when the piece moves.
</figcaption>
</figure>
<p>It is often the case that robots must interact with moving objects
(e.g., parts on a conveyor belt, other robots). For these situations, it
is often advantageous to explicitly include the notion of time in the
representation. For example, a robot that plays table tennis should be
able to estimate not only the instantaneous position of the ball at any
moment in time, but also the trajectory of the ball, thus enabling the
prediction of where the ball will be at future moments in time. In this
case, if we represent the coordinates of the ball by a vector
<span class="math notranslate nohighlight">\(x \in \mathbb{R}^3\)</span>, we make explicit the dependence on time by writing
<span class="math notranslate nohighlight">\(x(t)\)</span>. Furthermore, if we are interested also in the velocity of the
ball, we write <span class="math notranslate nohighlight">\(\dot{x}(t) = \frac{d}{ dt} x(t)\)</span> to denote the time
derivative of the ball’s position. Under the laws of Newtonian physics,
the position and velocity of the ball at any moment in time completely
determine the future trajectory of the ball (assuming no effects of
wind, etc.). In the vocabulary of physics, the <em>state</em> of a system is a
collection of information sufficient to determine the entire future
evolution of the system behavior. For this reason, in physics, one
refers to the pair <span class="math notranslate nohighlight">\((x,\dot{x})\)</span> as the state of the ball. Our use of
the term <em>state</em> is somewhat more general than that used to describe
physical systems; however the intuition behind both terms is essentially
the same.</p>
<p>As an example, Figure
<a href="#fig:chap1-projectile" data-reference-type="ref" data-reference="fig:chap1-projectile">4</a>
illustrates basic projectile motion. If the position and velocity of the
ball are both known at either time <span class="math notranslate nohighlight">\(t_0\)</span> or at time <span class="math notranslate nohighlight">\(t_1\)</span>, then it is
possible to predict the position and velocity of the ball at any future
moment in time. Although this example is fairly simple, in many robotics
applications the system’s state is represented using position and
velocity. This idea applies not only to various moving objects in the
environment, but even to the motion of the robot itself. This is the
case for robot arms, whose motion depends on torques generated by
motors, and for unmanned air vehicles (UAVs) such as quadrotors, whose
motion depends on aerodynamic forces generated by spinning propellers.</p>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures1/projectile.jpg?raw=1" title="fig:" id="fig:chap1-projectile" style="width:12.5cm" alt="" />
<figcaption>The motion of a ball follows the arc of a parabola. Given the position and velocity at any moment in time, it is possible to exactly predict the position and velocity at any future moment in time.
</figcaption>
</figure>
<p>It is often the case that discrete time representations are preferable
to using continuous time. This is because many algorithms used in
robotics rely on numerical methods to compute solutions. This should not
be surprising, since computer algorithms are by their nature
discrete-time entities. In this case, we use the notation <span class="math notranslate nohighlight">\(x_t\)</span> to
denote the value of the state <span class="math notranslate nohighlight">\(x\)</span> at time instant <span class="math notranslate nohighlight">\(t\)</span>. Often, we can
compute exact discrete-time system representations by integrating an
appropriate description of the system dynamics, such as</p>
<div class="math notranslate nohighlight">
\[x_{t+1} = x_t + \int_t^{t + 1} \dot{x}(t) dt\]</div>
<p>It is often the case that the robot does not have access to a complete
and correct model of its environment. For example, if sensors are used
to determine the world state, there will invariably be errors and
uncertainties associated to the sensor measurements. There are a variety
of ways that one can deal with such uncertainties. We can include
uncertainty explicitly in our representations, e.g., using tools from
probability theory, or we can incorporate uncertainty into our model of
the robot’s actions in the world. We will consider both of these options
in later chapters.</p>
</div>
<div class="section" id="representing-the-robot-s-state">
<h2><span class="section-number">1.1.2. </span>Representing the Robot’s State<a class="headerlink" href="#representing-the-robot-s-state" title="Permalink to this headline">¶</a></h2>
<p>While the robot is, technically, an object within the world, it enjoys
the special status of being able to act in the world to effect changes.
Furthermore, the robot has direct control over its own actions, unlike
obstacles or other actors in the world, over which the robot has, at
best, indirect control. Therefore, rather than merely incorporate
information about the robot into the world state, we typically represent
the robot state separately, using representations that are specifically
developed for modeling the robot’s geometry, dynamics, and manipulation
capabilities.</p>
<p>The most basic information about a robot’s state is merely a description
of the robot’s location in its environment. Four examples are shown in
Figure
<a href="#fig:chap1-four-robots" data-reference-type="ref" data-reference="fig:chap1-four-robots">5</a>.
For a vacuum cleaning robot, Figure
<a href="#fig:chap1-four-robots" data-reference-type="ref" data-reference="fig:chap1-four-robots">5</a>a,
this could be a set of <span class="math notranslate nohighlight">\(x,y\)</span> coordinates of the robot’s centroid with
respect to a floor plan of the house. For a robot arm, Figure
<a href="#fig:chap1-four-robots" data-reference-type="ref" data-reference="fig:chap1-four-robots">5</a>b,
we might specify a vector of joint angles. For a UAV, Figure
<a href="#fig:chap1-four-robots" data-reference-type="ref" data-reference="fig:chap1-four-robots">5</a>c,
we might specifiy the <span class="math notranslate nohighlight">\(x,y,z\)</span> coordinates of the vehicle, along with its
orientation. For a humanoid robot, Figure
<a href="#fig:chap1-four-robots" data-reference-type="ref" data-reference="fig:chap1-four-robots">5</a>d,
we might specify the position and orientation of the torso’s centroid,
along with a vector of angles for each of the robot’s joints. In
robotics, all of these correspond to the general notion of a robot’s
<em>configuration</em>. More precisely, a configuration <span class="math notranslate nohighlight">\(q\)</span> of the robot
provides a complete specification of the location of every point on the
robot with respect to a reference frame. The set of all configurations
is called the <em>configuration space</em>, and is denoted by <span class="math notranslate nohighlight">\(\cal Q\)</span>.</p>
<figure>
<img src="https://github.com/gtbook/robotics/blob/main/Figures1/four-robot-cspaces.jpg?raw=1" title="fig:" id="fig:chap1-four-robots" style="width:12.5cm" alt="" />
<figcaption>Configurations for for different robots. (a) A vacuum cleaning robot whose configuration is specified by x,y coordinates in the world frame. (b) A two-link robot arm, whose configuration is specified by its two joint angles (<i>&theta;<sub>1</sub>,&theta;<sub>2</sub></i>). (c) A quadrotor, whose configuration is specified by three position parameters x,y,z and three orientation parameters <i>&phi;,&theta;,&psi;</i>. (d) A humanoid robot whose configuration is specified by the position and orientation of the body-attached frame <i>x,y,z,&phi;,&theta;,&psi;</i> and the joint angles in the legs <i>&theta;<sub>1</sub>, &theta;<sub>2</sub>, &theta;<sub>3</sub>, &theta;<sub>4</sub></i>.
</figcaption>
</figure><p>A common way to define a robot’s configuration is to rigidly attach a
coordinate frame to each component of the robot that can move, and to
then specify the position and orientation of each of these frames. Of
the examples given above, we can consider the vacuum cleaning robot and
the UAV to be single rigid objects. For the vacuum cleaning robot,
assuming that the orientation of the robot is not of concern, we would
have <span class="math notranslate nohighlight">\(q = (x,y)\)</span>, for a UAV we might use <span class="math notranslate nohighlight">\(q = (x,y,z,\phi,\theta,\psi)\)</span>,
where the latter three parameters specify the orientation of the three
axes of the UAV’s body-attached coordinate frame with respect to a
reference frame.</p>
<p>For many robots, motion of the individual components is constrained by
the design of the mechanical system. For example, the motion of any link
in a robot arm is determined by the rotation of a single motor that
connects this link to the previous link. In such cases, a single
parameter (in this case a joint angle) is sufficient to specify the
configuration of the link, and the configuration of the entire robot arm
can be specified by <span class="math notranslate nohighlight">\(q = (\theta_1, \cdots , \theta_n)\)</span>, in the case of
an arm with <span class="math notranslate nohighlight">\(n\)</span> revolute joints (i.e., each joint is driven by a
rotating motor). More complex mechanisms require a combination of these
methods. For example, the configuration of a humanoid robot might be
represented by
<span class="math notranslate nohighlight">\(q = (x,y,z,\phi,\theta,\psi,\theta_1, \dots , \theta_n)\)</span>, in which the
first six parameters specify the position and orientation of a
body-attached frame (e.g., located at the centroid of the torso), and
<span class="math notranslate nohighlight">\(\theta_1, \cdots, \theta_n\)</span> specify the angles for the individual
joints of the robot. In later chapters, we will investigate the
configuration spaces for a variety of robots, from simple wheeled mobile
robots to more complex mobile manipulators comprised of moving platforms
with an attached manipulator arm.</p>
<p>The configuration of a robot answers the question of where the robot is
at a specific instant in time. If we wish instead to describe the motion
of a robot, we must consider the configuration to be time varying, and
in this case both the configuration and its time derivative (a velocity)
are relevant. As was the case above for moving objects, we often package
the configuration and its time derivative into a single vector</p>
<div class="math notranslate nohighlight">
\[\begin{split}x(t) = \left[ \begin{array}{c} q(t) \\ \dot{q}(t) \end{array}\right]\end{split}\]</div>
<p>In many disciplines related to robotics, <span class="math notranslate nohighlight">\(x\)</span> is referred to as the
state. This is particularly true in the areas of dynamical systems and
control theory. In this text, we will maintain a more general use of the
term <em>state</em>, but when relevant, we will adopt discipline-appropriate
terminology (e.g., when describing how to control a robot’s motion).</p>
<p>In many applications, position and velocity provide a sufficiently
detailed description of robot motion. This is not true, however, when we
must explicitly consider forces that affect the robot’s motion. For
example, we can essentially regard a vacuum cleaning robot as a device
that responds to position and velocity commands: we issue a command to
the robot to move to a certain position at a certain velocity, and the
robot has no difficulty in executing this command. There are, however,
numerous applications in which simple geometric descriptions of robot
motion are not adequate. Consider for example the case of a quadrotor
that maneuvers by exploiting aerodynamic forces, or a humanoid robot
whose locomotion depends on interaction forces between its feet and the
ground. In these cases, we typically consider position, velocity, and
acceleration, i.e., in terms of <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(\dot{x}\)</span>, or, if making the
configuration and its derivatives more explicit, in terms of
<span class="math notranslate nohighlight">\(q, \dot{q},\)</span> and <span class="math notranslate nohighlight">\(\ddot{q}\)</span>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="S10_introduction.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">1. </span>Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="S12_intro_actions.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1.2. </span>Robot Actions</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Frank Dellaert and Seth Hutchinson<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>